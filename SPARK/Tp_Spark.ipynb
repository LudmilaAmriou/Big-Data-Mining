{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxIzvnKxTET5"
      },
      "outputs": [],
      "source": [
        "# Installation de Java\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Installation du fichier Spark\n",
        "\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# Extraction a partir du fichier Zip\n",
        "\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "# Installation du module Spark pour permettre d'utiliser Spark avec Python\n",
        "\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création d'une session Spark"
      ],
      "metadata": {
        "id": "-9l5hIDz1wPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation de l'environnement de travail \n",
        "\n",
        "import os\n",
        "import multiprocessing as mp \n",
        "import threading as th \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "# Importation du module findspark et sparkcontext\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "MAX_MEMORY = \"5g\"\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"TP_Taibi_Toumi\") \\\n",
        ".config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
        ".config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "VaFwTNwqUGoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "a26V9LJjZJiA",
        "outputId": "0dfc5086-fcb6-49b9-ff7b-8fad9aeadfbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9db1b95640>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4571dce5a325:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>TP_Taibi_Toumi</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from math import sqrt\n",
        "import time\n",
        "import pandas as pd\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "0XmPMGt_iZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création d'un dataframe sur IRIS"
      ],
      "metadata": {
        "id": "yF02BqIq16z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('IRIS.csv')"
      ],
      "metadata": {
        "id": "_RJALSzI_RTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f2bxNvH_ysF",
        "outputId": "4608534b-eca4-412b-a66d-3f5bb65d1a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création d'un spark Dataframe"
      ],
      "metadata": {
        "id": "nHn7hBYc2FVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark.createDataFrame(df2)\n",
        "# Printing Schema\n",
        "spark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODm3G3moih2S",
        "outputId": "2a696820-c8c1-40ef-eddb-f2c217f475e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17iM6j8ZjRca",
        "outputId": "3a3de09a-3445-4546-feec-b9797dd923b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallélisation du travail de sparks sur les cores du processeur"
      ],
      "metadata": {
        "id": "1vNeVi3a2KTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "rdd = sc.parallelize(df2.to_numpy()) # paralléliser le travail sur les cores de l'ordinateur\n",
        "print(\"nombre de partitions : \"+ str(rdd.getNumPartitions()));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkWt2_xlzmxH",
        "outputId": "48c6479b-ffc7-4675-876a-5a5d70fb8a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nombre de partitions : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Première itération de k-means"
      ],
      "metadata": {
        "id": "FLplgdlo27JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global NB_CLUSTERS\n",
        "NB_CLUSTERS = 3\n",
        "rdd_data = spark_df.rdd\n",
        "initial_centroids = rdd_data.takeSample(False, NB_CLUSTERS)\n",
        "#print(\"init centroid execution:\", len(initial_centroids), \"in\", (time.time() - start_time\n",
        "# Converting centroids dataframe into dictionary indexed with centroid's number : 0 = firs\n",
        "i = 0\n",
        "for ctr in initial_centroids:\n",
        "    initial_centroids[i] = [ctr['sepal_length'],ctr['sepal_width'],ctr['petal_length'],ctr['petal_width']]\n",
        "    i += 1\n",
        "# Print centroids values\n",
        "print(initial_centroids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsqMfOJ1jVrq",
        "outputId": "4839462f-883f-4ec5-f0d0-84ea9e100f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.6, 3.0, 4.4, 1.4], [5.4, 3.4, 1.7, 0.2], [5.0, 3.6, 1.4, 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculer la distance euclidienne et trouver le centroid le plus proche pour k-means"
      ],
      "metadata": {
        "id": "idTTmLvc2vjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mapper:\n",
        "  def dist_centroids(self, dict_centroids, point):\n",
        "    # Initializing the min. distance with a large value so that all calculated values woul\n",
        "    min_dist = float(\"inf\")\n",
        "    # Initializing nearest centroid to 0\n",
        "    nearest_centroid = 0\n",
        "    for i in range(len(dict_centroids)):\n",
        "    # Retreive centroid number i\n",
        "     centroid = dict_centroids[i]\n",
        "    # Calculate euclidean distance between points and centroids\n",
        "    distance = sqrt( (point['sepal_length']-centroid[0])**2 + (point['sepal_width']-centroid[1])**2 + (point['petal_length']-centroid[2])**2 +  (point['petal_width']-centroid[3])**2 )\n",
        "    if(distance < min_dist):\n",
        "      min_dist = distance\n",
        "      nearest_centroid = i\n",
        "    return (nearest_centroid, point)"
      ],
      "metadata": {
        "id": "5Hfn8WcMlcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appliquation du k-means avec une architecture parallèle"
      ],
      "metadata": {
        "id": "e2wgIUvW3F_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = Mapper()\n",
        "p = rdd_data.take(3)\n",
        "pt = p[0]\n",
        "result = m.dist_centroids(initial_centroids, pt)\n",
        "print(result)\n",
        "#afficher le nombre de cores utilisé \n",
        "print(mp.cpu_count())\n",
        "#afficher le nombre de threads \n",
        "print(th.active_count())"
      ],
      "metadata": {
        "id": "i3a7GVT9l0ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d563fa3-f5a2-40af-ed1e-fe3be33d5f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, Row(sepal_length=5.1, sepal_width=3.5, petal_length=1.4, petal_width=0.2, species='Iris-setosa'))\n",
            "2\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(initial_centroids)\n",
        "print(pt)\n",
        "# Afficher le nombre de partitions de l'ensemble de données data\n",
        "print(\"Nombre de partitions de l'ensemble de données : \", rdd_data.getNumPartitions())\n",
        "# Fin du chronomètre\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHC4x2b-l5Fq",
        "outputId": "9e31280e-ed31-44b5-db07-7b8f912e20bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.6, 3.0, 4.4, 1.4], [5.4, 3.4, 1.7, 0.2], [5.0, 3.6, 1.4, 0.2]]\n",
            "Row(sepal_length=5.1, sepal_width=3.5, petal_length=1.4, petal_width=0.2, species='Iris-setosa')\n",
            "Nombre de partitions de l'ensemble de données :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Affichage du temps d'éxecution"
      ],
      "metadata": {
        "id": "ZMbh8mLN3gQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher le temps d'exécution\n",
        "print(\"Temps d'exécution : \", end_time - start_time, \"secondes\")\n",
        "new_rdd = rdd_data.map(lambda x: [m.dist_centroids(initial_centroids[i], x) for i in range])\n",
        "# Arrêter la SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMPYvDlLl9ME",
        "outputId": "1f506cfa-5320-4753-8116-15daf26a45da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temps d'exécution :  24.681127071380615 secondes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIXpZ5zr32Wr",
        "outputId": "ec6c2915-fe47-41ac-95ba-6b1019055e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}